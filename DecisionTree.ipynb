{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZImaV9RzEiA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAbVm7V4zi9k"
      },
      "source": [
        "class Node:\n",
        "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
        "        self.gini = gini\n",
        "        self.num_samples = num_samples\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.predicted_class = predicted_class\n",
        "        self.feature_index = 0\n",
        "        self.threshold = 0\n",
        "        self.left = None\n",
        "        self.right = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUf-yg7IzIWx"
      },
      "source": [
        "class DecisionTree:\n",
        "\n",
        "  def __init__(self, X, y, num_classes):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.num_classes = num_classes\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y)\n",
        "\n",
        "  def find_split(self, X, y, n_classes):\n",
        "    \"\"\" Find split where children has lowest impurity possible\n",
        "    in condition where the purity should also be less than the parent,\n",
        "    if not, stop.\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "    if n_samples <= 1:\n",
        "          return None, None\n",
        "    \n",
        "    #so it will not have any warning about \"referenced before assignments\"\n",
        "    feature_ix, threshold = None, None\n",
        "    \n",
        "    # Count of each class in the current node.\n",
        "    sample_per_class_parent = [np.sum(y == c) for c in range(n_classes)] #[2, 2]\n",
        "    \n",
        "    # Gini of parent node.\n",
        "    best_gini = 1.0 - sum((n / n_samples) ** 2 for n in sample_per_class_parent)\n",
        "\n",
        "    # Loop through all features.\n",
        "    for feature in range(n_features):\n",
        "        \n",
        "        # Sort data along selected feature.\n",
        "        sample_sorted = sorted(X[:, feature]) #[2, 3, 10, 19]\n",
        "        sort_idx = np.argsort(X[:, feature])\n",
        "        y_sorted = y[sort_idx] #[0, 0, 1, 1]\n",
        "                \n",
        "        sample_per_class_left = [0] * n_classes   #[0, 0]\n",
        "        \n",
        "        sample_per_class_right = sample_per_class_parent.copy() #[2, 2]\n",
        "        \n",
        "        #loop through each threshold, 2.5, 6.5, 14.5\n",
        "        #1st iter: [-] [-++]\n",
        "        #2nd iter: [--] [++]\n",
        "        #3rd iter: [--+] [+]\n",
        "        for i in range(1, n_samples): #1 to 3 (excluding 4)\n",
        "            #the class of that sample\n",
        "            c = y_sorted[i - 1]  #[0]\n",
        "            \n",
        "            #put the sample to the left\n",
        "            sample_per_class_left[c] += 1  #[1, 0]\n",
        "                        \n",
        "            #take the sample out from the right  [1, 2]\n",
        "            sample_per_class_right[c] -= 1\n",
        "            \n",
        "            gini_left = 1.0 - sum(\n",
        "                (sample_per_class_left[x] / i) ** 2 for x in range(n_classes)\n",
        "            )\n",
        "                        \n",
        "            #we divided by n_samples - i since we know that the left amount of samples\n",
        "            #since left side has already i samples\n",
        "            gini_right = 1.0 - sum(\n",
        "                (sample_per_class_right[x] / (n_samples - i)) ** 2 for x in range(n_classes)\n",
        "            )\n",
        "\n",
        "            #weighted gini\n",
        "            weighted_gini = ((i / n_samples) * gini_left) + ( (n_samples - i) /n_samples) * gini_right\n",
        "\n",
        "            # in case the value are the same, we do not split\n",
        "            # (both have to end up on the same side of a split).\n",
        "            if sample_sorted[i] == sample_sorted[i - 1]:\n",
        "                continue\n",
        "            if weighted_gini < best_gini:\n",
        "                \n",
        "                best_gini = weighted_gini\n",
        "                feature_ix = feature\n",
        "                threshold = (sample_sorted[i] + sample_sorted[i - 1]) / 2  # midpoint\n",
        "\n",
        "      #return the feature number and threshold \n",
        "      #used to find best split\n",
        "    return feature_ix, threshold\n",
        "\n",
        "  def fit(self, Xtrain, ytrain, n_classes, max_depth, depth=0):  \n",
        "      n_samples, n_features = Xtrain.shape\n",
        "      num_samples_per_class = [np.sum(ytrain == i) for i in range(n_classes)]\n",
        "      #predicted class using the majority of sample class\n",
        "      predicted_class = np.argmax(num_samples_per_class)\n",
        "      \n",
        "      #define the parent node\n",
        "      node = Node(\n",
        "          gini = 1 - sum((np.sum(y == c) / n_samples) ** 2 for c in range(n_classes)),\n",
        "          predicted_class=predicted_class,\n",
        "          num_samples = ytrain.size,\n",
        "          num_samples_per_class = num_samples_per_class,\n",
        "          )\n",
        "\n",
        "      #perform recursion\n",
        "      feature, threshold = self.find_split(Xtrain, ytrain, n_classes)\n",
        "      if depth < max_depth :\n",
        "          #take all the indices that is less than threshold\n",
        "        if feature is not None :\n",
        "          indices_left = X[:, feature] < threshold\n",
        "          X_left, y_left = X[indices_left], y[indices_left]\n",
        "          X_right, y_right = X[~indices_left], y[~indices_left]\n",
        "          node.feature_index = feature\n",
        "          node.threshold = threshold\n",
        "          node.left = self.fit(X_left, y_left, n_classes, max_depth, depth + 1)\n",
        "          node.right = self.fit(X_right, y_right, n_classes, max_depth, depth + 1)\n",
        "      return node\n",
        "\n",
        "  #to predict, it is as simple as moving \n",
        "  #through the tree \n",
        "  def predict(self, sample, tree):\n",
        "      while tree.left:\n",
        "          if sample[tree.feature_index] < tree.threshold:\n",
        "              tree = tree.left\n",
        "          else:\n",
        "              tree = tree.right\n",
        "      return tree.predicted_class\n",
        "\n",
        "  def output(self, max_depth):\n",
        "    tree = self.fit(self.X_train, self.y_train, self.num_classes, max_depth)\n",
        "    prediction = [self.predict(x, tree) for x in exp.X_test]\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf_UtxRHle25",
        "outputId": "c2015f79-df7d-4b6b-a98d-d08ae7e88e04"
      },
      "source": [
        "a = np.array([1, 2, 1, 2])\n",
        "b = np.array([1, 2, 2, 2])\n",
        "(a[a == b]).shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO3OdOWHzNF1",
        "outputId": "545bd756-170b-4430-e5ee-640d822b2307"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "exp = DecisionTree(X, y, 3)\n",
        "y_predict = exp.output(20)\n",
        "acc = (exp.y_test[y_predict == exp.y_test]).shape[0] / exp.y_test.shape[0]\n",
        "print('Accuracy = ', acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.5526315789473685\n"
          ]
        }
      ]
    }
  ]
}