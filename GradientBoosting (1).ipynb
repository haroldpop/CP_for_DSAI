{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoosting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZxcJypI0CZ7"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.dummy import DummyClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvUzWmehoXQ1"
      },
      "source": [
        "def multinomial_encoder(y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    m, n = y.shape\n",
        "    nb_class = np.unique(y).shape[0]\n",
        "    #we got number from 0 to 9\n",
        "    y_encod = np.zeros((m, nb_class))\n",
        "    for k in range(m):\n",
        "        class_ = y[k]\n",
        "        y_encod[k, class_] += 1\n",
        "    return y_encod"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrfygQZylPmP"
      },
      "source": [
        "class GradientBoosting:\n",
        "\n",
        "    def __init__(self, method, n_estimators, tree_params, learning_rate):\n",
        "        if method not in ['regression', 'binary', 'multinomial'] :\n",
        "            raise ValueError('Please select a method between regression, binary and multinomial')\n",
        "        self.method = method\n",
        "        self.learning_rate = learning_rate\n",
        "        self.models = [DecisionTreeRegressor(**tree_params) for _ in range(n_estimators)]\n",
        "\n",
        "    def grad(self, y, h):\n",
        "        return y - h\n",
        "\n",
        "    def softmax(self, z):\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis = 1, keepdims=True)\n",
        "\n",
        "\n",
        "    def predict(self, X, models):\n",
        "        learning_rate = self.learning_rate  ##hard code for now\n",
        "        if self.method == 'regression' :\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            yhat = f0 + boosting\n",
        "        elif self.method == 'binary':\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            yhat = f0 + boosting\n",
        "            yhat = expit(yhat)\n",
        "        else :\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            yhat = f0 + boosting\n",
        "            yhat = self.softmax(yhat)\n",
        "        return yhat\n",
        "\n",
        "    def fit_data(self, X, y):\n",
        "        models_trained = []\n",
        "        #using DummyRegressor is a good technique for starting model\n",
        "        if self.method == 'regression':\n",
        "            first_model = DummyRegressor(strategy = 'mean')\n",
        "        else :  \n",
        "            first_model = DummyClassifier(strategy='stratified')\n",
        "        first_model.fit(X, y)\n",
        "        models_trained.append(first_model)\n",
        "        #fit the estimators\n",
        "        for i, model in enumerate(self.models):\n",
        "            #predict using all the weak learners we trained up to\n",
        "            #this point\n",
        "            y_pred = self.predict(X, models_trained)\n",
        "            #errors will be the total errors maded by models_trained\n",
        "            residual = self.grad(y, y_pred)\n",
        "            #fit the next model with residual\n",
        "            model.fit(X, residual)\n",
        "            models_trained.append(model)\n",
        "        return models_trained"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWRa4ByBpm6h"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49SOrYvoqUz",
        "outputId": "499af9b2-87b5-438c-eb69-95e6e8a7db37"
      },
      "source": [
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators = 200\n",
        "tree_params = {'max_depth': 4, 'min_samples_split': 2}\n",
        "exp = GradientBoosting('regression', n_estimators, tree_params, learning_rate=0.1)\n",
        "\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "\n",
        "#print metrics\n",
        "print(\"Our MSE: \", mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our MSE:  8.174844777503699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t34pWBl57Med"
      },
      "source": [
        "If we tweak a little bit with *max_depth* and *min_samples_split* parameters, we can achieve better performance. The maximum depth of the tree is the most influent parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm0A3Je0q8OY"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih4OYczJpu7B",
        "outputId": "fc41d7b6-7d26-4ee8-cead-ebf44276635e"
      },
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators = 200\n",
        "tree_params = {'max_depth': 3, 'min_samples_split': 2}\n",
        "learning_rate = 0.1\n",
        "exp = GradientBoosting('binary', n_estimators, tree_params, learning_rate)\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "y_pred = np.round(y_pred)\n",
        "#print metrics\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95        63\n",
            "           1       0.98      0.96      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.96      0.97      0.96       171\n",
            "weighted avg       0.97      0.96      0.97       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R45jiAFq_s6"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "rfWdf-W4q-oH",
        "outputId": "3ae900eb-67b9-4c08-8480-8464ed60488c"
      },
      "source": [
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "n_estimators = 200\n",
        "y_train = multinomial_encoder(y_train)\n",
        "tree_params = {'max_depth': 8, 'min_samples_split': 4}\n",
        "learning_rate = 0.1\n",
        "exp = GradientBoosting('multinomial', n_estimators, tree_params, learning_rate)\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "#print metrics\n",
        "print('Accuracy: ', y_test[y_pred == y_test].shape[0] / y_test.shape[0])\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.937037037037037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f17d59b2dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBuFqgH7rl5z"
      },
      "source": [
        "The multinomial method is the one which give the worst accuracy with the longest computation time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "2CEUCX05raWa",
        "outputId": "15367788-76f3-422f-a6e3-197656ca274d"
      },
      "source": [
        "exp = GradientBoosting('gaussian', n_estimators, tree_params, learning_rate)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d1a98ba371ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoosting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-b09b66a22d1b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, method, n_estimators, tree_params, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please select a method between regression, binary and multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please select a method between regression, binary and multinomial"
          ]
        }
      ]
    }
  ]
}