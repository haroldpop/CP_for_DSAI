{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoosting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZxcJypI0CZ7"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvUzWmehoXQ1"
      },
      "source": [
        "def multinomial_encoder(y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    m, n = y.shape\n",
        "    nb_class = np.unique(y).shape[0]\n",
        "    #we got number from 0 to 9\n",
        "    y_encod = np.zeros((m, nb_class))\n",
        "    for k in range(m):\n",
        "        class_ = y[k]\n",
        "        y_encod[k, class_] += 1\n",
        "    return y_encod"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrfygQZylPmP"
      },
      "source": [
        "class GradientBoosting:\n",
        "\n",
        "    def __init__(self, method, n_estimators, tree_params, learning_rate):\n",
        "        if method not in ['regression', 'binary', 'multinomial'] :\n",
        "            raise ValueError('Please select a method between regression, binary and multinomial')\n",
        "        self.method = method\n",
        "        self.learning_rate = learning_rate\n",
        "        if self.method == 'regression':\n",
        "            self.models = [DecisionTreeRegressor(**tree_params) for _ in range(n_estimators)]\n",
        "        else :\n",
        "            self.models = [DecisionTreeClassifier(**tree_params) for _ in range(n_estimators)]\n",
        "\n",
        "    def grad(self, y, h):\n",
        "        return y - h\n",
        "\n",
        "    def softmax(self, z):\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis = 1, keepdims=True)\n",
        "\n",
        "\n",
        "    def predict(self, X, models):\n",
        "        learning_rate = self.learning_rate  ##hard code for now\n",
        "        if self.method == 'regression' :\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            return f0 + boosting\n",
        "        elif self.method == 'binary':\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            yhat = f0 + boosting\n",
        "            yhat =  np.round(expit(yhat))\n",
        "            return yhat\n",
        "        else :\n",
        "            f0 = models[0].predict(X)  #first use the dummy model\n",
        "            boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
        "            yhat = f0 + boosting\n",
        "            yhat = self.softmax(yhat)\n",
        "            yhat = np.argmax(yhat, axis = 1)\n",
        "            yhat = multinomial_encoder(yhat)\n",
        "            return yhat\n",
        "\n",
        "    def fit_data(self, X, y):\n",
        "        models_trained = []\n",
        "        #using DummyRegressor is a good technique for starting model\n",
        "        if self.method == 'regression':\n",
        "            first_model = DummyRegressor(strategy = 'mean')\n",
        "        else :  \n",
        "            first_model = DummyClassifier(strategy='stratified')\n",
        "        first_model.fit(X, y)\n",
        "        models_trained.append(first_model)\n",
        "        #fit the estimators\n",
        "        for i, model in enumerate(self.models):\n",
        "            #predict using all the weak learners we trained up to\n",
        "            #this point\n",
        "            y_pred = self.predict(X, models_trained)\n",
        "            #errors will be the total errors maded by models_trained\n",
        "            residual = self.grad(y, y_pred)\n",
        "            #fit the next model with residual\n",
        "            model.fit(X, residual)\n",
        "            models_trained.append(model)\n",
        "        return models_trained"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWRa4ByBpm6h"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49SOrYvoqUz",
        "outputId": "644e24b0-9348-496e-dfa4-9e47660cd830"
      },
      "source": [
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators = 200\n",
        "tree_params = {'max_depth': 4, 'min_samples_split': 2}\n",
        "exp = GradientBoosting('regression', n_estimators, tree_params, learning_rate=0.1)\n",
        "\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "\n",
        "#print metrics\n",
        "print(\"Our MSE: \", mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our MSE:  8.381549935416325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t34pWBl57Med"
      },
      "source": [
        "If we tweak a little bit with *max_depth* and *min_samples_split* parameters, we can achieve better performance. The maximum depth of the tree is the most influent parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm0A3Je0q8OY"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih4OYczJpu7B",
        "outputId": "a6fe5d51-321b-43e1-d3a4-546a8988bc58"
      },
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators = 200\n",
        "tree_params = {'max_depth': 3, 'min_samples_split': 2}\n",
        "learning_rate = 0.1\n",
        "exp = GradientBoosting('binary', n_estimators, tree_params, learning_rate)\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "#print metrics\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72        63\n",
            "           1       0.84      0.81      0.82       108\n",
            "\n",
            "    accuracy                           0.78       171\n",
            "   macro avg       0.77      0.78      0.77       171\n",
            "weighted avg       0.79      0.78      0.79       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R45jiAFq_s6"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "rfWdf-W4q-oH",
        "outputId": "bf3f5c39-6282-4bc2-8987-458a23ce9f40"
      },
      "source": [
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "n_estimators = 200\n",
        "y_train = multinomial_encoder(y_train)\n",
        "tree_params = {'max_depth': 8, 'min_samples_split': 4}\n",
        "learning_rate = 0.1\n",
        "exp = GradientBoosting('multinomial', n_estimators, tree_params, learning_rate)\n",
        "\n",
        "#fit the models\n",
        "models = exp.fit_data(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "y_pred = exp.predict(X_test, models)\n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "#print metrics\n",
        "print('Accuracy: ', y_test[y_pred == y_test].shape[0] / y_test.shape[0])\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7018518518518518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7700fcd190>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBuFqgH7rl5z"
      },
      "source": [
        "The multinomial method is the one which give the worst accuracy with the longest computation time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "2CEUCX05raWa",
        "outputId": "046726be-017c-4145-beda-e33840661c9d"
      },
      "source": [
        "exp = GradientBoosting('gaussian', n_estimators, tree_params, learning_rate)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-d1a98ba371ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoosting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-157-462016a072a9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, method, n_estimators, tree_params, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please select a method between regression, binary and multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please select a method between regression, binary and multinomial"
          ]
        }
      ]
    }
  ]
}