{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fc808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38a7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ef3d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class Bagging :\n",
    "    def __init__(self, B, bootstrap_ratio, max_depth, criterion, min_samples_split, replacement):\n",
    "        self.B = B\n",
    "        self.bootstrap_ratio = bootstrap_ratio\n",
    "        self.replacement = replacement\n",
    "        tree_params = {'max_depth': max_depth, 'criterion': criterion, 'min_samples_split': min_samples_split, 'max_features': 'sqrt'}\n",
    "        self.models  = [DecisionTreeClassifier(**tree_params) for _ in range(B)]\n",
    "    \n",
    "    def fit(self, X, y) :\n",
    "        sample_size = int(self.bootstrap_ratio * len(X))\n",
    "        m, n = X.shape\n",
    "        B = self.B\n",
    "        xsamples = np.zeros((B, sample_size, n))\n",
    "        ysamples = np.zeros((B, sample_size))\n",
    "        #subsamples for each model\n",
    "        oob = []\n",
    "        y_oob = []\n",
    "        for i in range(B):\n",
    "            ##sampling with replacement; i.e., sample can occur more than once\n",
    "            #for the same predictor\n",
    "            idx_list = []\n",
    "            for j in range(sample_size):\n",
    "                idx = random.randrange(m)   #<----with replacement #change so no repetition\n",
    "                if self.replacement == True:\n",
    "                    if idx in idx_list :\n",
    "                        #I don't know if there is a numpy command which can return an array like np.arange(m) without the values present in idx_list\n",
    "                        #it would avoid to pick from an array with already forbidden values\n",
    "                        idx_possibilities = np.arange(m)\n",
    "                        idx_possibilities = np.delete(idx_possibilities, idx)\n",
    "                        while idx in idx_list :\n",
    "                            idx = random.choice(idx_possibilities)        \n",
    "                xsamples[i, j, :] = X_train[idx]\n",
    "                ysamples[i, j] = y_train[idx]\n",
    "                idx_list.append(idx)\n",
    "                #keep track of idx that i did not use for ith tree\n",
    "            idx_list = np.array(idx_list)\n",
    "            oob.append(X_train[~idx_list])\n",
    "            y_oob.append(y_train[~idx_list])\n",
    "        oob = np.array(oob)\n",
    "        #calculate score for oob evaluation for bootstrapped dataset\n",
    "        oob_predictions = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            _X = xsamples[i, :]\n",
    "            _y = ysamples[i, :]\n",
    "            model.fit(_X, _y)\n",
    "            predictions = np.zeros(oob[i].shape[0])\n",
    "            yhat = model.predict(oob[i])\n",
    "            oob_predictions.append(yhat)\n",
    "        oob_acc = np.zeros(len(oob_predictions))\n",
    "        for i in range(len(oob_predictions)):\n",
    "            acc = (y_oob[i][y_oob[i] == oob_predictions[i]]).shape[0] / y_oob[i].shape[0]\n",
    "            oob_acc[i] = acc\n",
    "            \n",
    "        print('Oob accuracy for each dataset : ', oob_acc)\n",
    "        print('Oob average accuracy : ', np.mean(oob_acc))\n",
    "        return model\n",
    "              \n",
    "    def predictions(self, X_train, y_train, X_test) :\n",
    "        model = self.fit(X_train, y_train)\n",
    "        predictions = np.zeros((self.B, X_test.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            yhat = model.predict(X_test)\n",
    "            predictions[i, :] = yhat\n",
    "        yhat = stats.mode(predictions)[0][0]\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcb09818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oob accuracy for each dataset :  [0.81904762 0.94285714 0.94285714 0.94285714 0.94285714]\n",
      "Oob average accuracy :  0.9180952380952382\n",
      "Accuracy :  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "exp = Bagging(5, 1, 2, 'gini', 5, True)\n",
    "yhat = exp.predictions(X_train, y_train, X_test)\n",
    "print('Accuracy : ', y_test[y_test == yhat].shape[0] / y_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
